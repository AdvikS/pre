% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pre.R
\name{pre}
\alias{pre}
\title{Derive a prediction rule ensemble}
\usage{
pre(formula, data, weights = rep(1, times = nrow(data)), type = "both",
  sampfrac = 0.5, maxdepth = 3L, learnrate = NULL, mtry = Inf,
  ntrees = 500, removecomplements = TRUE, removeduplicates = TRUE,
  winsfrac = 0.025, normalize = TRUE, standardize = FALSE, nfolds = 10L,
  verbose = FALSE, par.init = FALSE, par.final = FALSE,
  tree.control = ctree_control(maxdepth = maxdepth, mtry = mtry), ...)
}
\arguments{
\item{formula}{a symbolic description of the model to be fit of the form 
\code{y ~ x1 + x2 + ...+ xn}. If the output variable (left-hand side of the 
formula) is a factor, an ensemble for binary classification is created.
Otherwise, an ensemble for prediction of a continuous variable is created. 
Note that input variables may not have 'rule' as (part of) their name, and 
the formula may not exclude the intercept (that is \code{+ 0} or \code{- 1} 
may not be used in the right-hand side of the formula).}

\item{data}{matrix or data.frame containing the variables in the model. When a
matrix is specified, it must be of class \code{"numeric"} (the input and output 
variable must be continuous; the input variables may be 0-1 coded variables). 
When a data.frame is specified, the output variable must be of 
class \code{"numeric"} and must be a continuous variable; the input variables 
must be of class \code{"numeric"} (for continuous input variables), 
\code{"logical"} (for binary variables), \code{"factor"} (for nominal input 
variables with 2 or more levels), or \code{"ordered" "factor"} (for 
ordered input variables).}

\item{weights}{an optional vector of observation weights to be used for 
deriving the ensemble.}

\item{type}{character. Type of base learners to be included in ensemble. 
Defaults to "both" (initial ensemble included both rules and linear functions). 
Other option may be "rules" (for prediction rules only) or "linear" (for 
linear functions only).}

\item{sampfrac}{numeric. Takes values \eqn{>0} and \eqn{\leq 1}, representing the 
fraction of randomly selected training observations used to produce each 
tree. Values \eqn{< 1} will result in subsamples being drawn without replacement 
(i.e., subsampling), a value of 1 will result in bootstrap sampling. 
Alteratively, users may supply their own sampling function like for example 
\code{\link{gpe_sample}}.}

\item{maxdepth}{numeric. Maximum number of conditions in rule}

\item{learnrate}{numeric. Learning rate for sequentially induced trees. If 
\code{NULL} (default), the learnrate is set to .01 for regression and to 0 
for classification. Setting the learning rate to values > 0 for classification 
dramatically increases computation time.}

\item{mtry}{numeric. Number of randomly selected predictor variables for 
creating each split in each tree.}

\item{ntrees}{numeric. Number of trees to generate for the initial ensemble.}

\item{removecomplements}{logical. Remove rules from the ensemble which have
the same support in the training data as the inverse of other rules?}

\item{removeduplicates}{logical. Remove rules from the ensemble which have 
the exact same support in training data?}

\item{winsfrac}{numeric. Quantiles of data distribution to be used for 
winsorizing linear terms. If set to 0, no winsorizing is performed. Note 
that ordinal variables are included as linear terms in estimating the
regression model, and will also be winsorized.}

\item{normalize}{logical. Normalize linear variables before estimating the 
regression model? Normalizing gives linear terms the same a priori influence 
as a typical rule, by dividing the (winsorized) linear term by 2.5 times its 
SD.}

\item{standardize}{logical. Standardize rules and linear terms before 
estimating the regression model? As this will also standardize dummy coded
factors, users are advised to use the default: \code{standardize = FALSE}.}

\item{nfolds}{numeric. Number of folds to be used in performing cross 
validation for determining penalty parameter.}

\item{verbose}{logical. Should information on the initial and final ensemble 
be printed to the command line?}

\item{par.init}{logical. Should parallel foreach be used to generate initial 
ensemble? Only used when \verb{learnrate == 0}. Must register parallel 
beforehand, such as doMC or others.}

\item{par.final}{logical. Should parallel foreach be used to perform cross 
validation for selecting the final ensemble? Must register parallel beforehand, 
such as doMC or others.}

\item{tree.control}{list with control parameters to be passed to the tree 
fitting function, see \code{\link[partykit]{ctree_control}]}.}

\item{...}{Additional arguments to be passed to 
\code{\link[glmnet]{cv.glmnet}}.}
}
\value{
an object of class \code{pre}
}
\description{
\code{pre} derives a sparse ensemble of rules and/or linear functions for 
prediction of a continuous or binary outcome.
}
\details{
Inputs can be continuous, ordered or factor variables. Output can be
continuous or binary categorical.
}
\note{
The code for deriving rules from the nodes of trees was taken from an 
internal function of the \code{partykit} package of Achim Zeileis and Torsten 
Hothorn.
}
\examples{
\donttest{
set.seed(42)
airq.ens <- pre(Ozone ~ ., data = airquality[complete.cases(airquality),], verbose = TRUE)}
}
\seealso{
\code{\link{print.pre}}, \code{\link{plot.pre}}, 
\code{\link{coef.pre}}, \code{\link{importance}}, \code{\link{predict.pre}}, 
\code{\link{interact}}, \code{\link{cvpre}}
}
